{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Union\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "\n",
    "def ensure_doc(\n",
    "    input: Union[str, List[str], spacy.tokens.doc.Doc], nlp: Union[Language, str], batch_size: int = 1000\n",
    ") -> spacy.tokens.doc.Doc:\n",
    "    \"\"\"Converts string or list inputs to spaCy docs.\n",
    "\n",
    "    Args:\n",
    "        input: A string, list of tokens, or a spaCy doc.\n",
    "        nlp: The language model to use.\n",
    "        batch_size: The number of texts to accumulate in an internal buffer.\n",
    "\n",
    "    Returns:\n",
    "        A spaCy doc, unannotated if derived from a string or list of tokens.\n",
    "    \"\"\"\n",
    "    if isinstance(input, spacy.tokens.doc.Doc):\n",
    "        return input\n",
    "    else:\n",
    "        if isinstance(nlp, str):\n",
    "            nlp = spacy.load(nlp)\n",
    "        if isinstance(input, str):\n",
    "            return list(nlp.tokenizer.pipe([input], batch_size=batch_size))[0]\n",
    "        elif isinstance(input, list):\n",
    "            return list(nlp.tokenizer.pipe([\" \".join(input)], batch_size=batch_size))[0]\n",
    "        else:\n",
    "            raise Exception(\"Bad data type.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Bad data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m doc2 \u001b[38;5;241m=\u001b[39m \u001b[43mensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(doc2))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m doc2:\n",
      "Cell \u001b[1;32mIn[45], line 29\u001b[0m, in \u001b[0;36mensure_doc\u001b[1;34m(input, nlp, batch_size)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(nlp\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpipe([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28minput\u001b[39m)], batch_size\u001b[38;5;241m=\u001b[39mbatch_size))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBad data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Bad data type."
     ]
    }
   ],
   "source": [
    "doc2 = ensure_doc(123, \"en_core_web_sm\")\n",
    "print(type(doc2))\n",
    "for t in doc2:\n",
    "    print(t.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "isinstance(3.2, Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from pydantic import (\n",
    "    BaseModel,\n",
    "    ValidationError,\n",
    ")\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from typing import Protocol\n",
    "\n",
    "class Windows(Protocol):\n",
    "    windows = 1\n",
    "\n",
    "class AveragesModel(BaseModel):\n",
    "    patterns: Union[list, str]\n",
    "    windows: Windows\n",
    "    search_method: str\n",
    "    nlp: spacy.vocab.Vocab\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for AveragesModel\nwindows\n  instance of Windows expected (type=type_error.arbitrary_type; expected_arbitrary_type=Windows)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mAveragesModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\scott\\envs\\lexos\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for AveragesModel\nwindows\n  instance of Windows expected (type=type_error.arbitrary_type; expected_arbitrary_type=Windows)"
     ]
    }
   ],
   "source": [
    "a = AveragesModel(patterns=1, windows=[], search_method=\"x\", nlp=nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
